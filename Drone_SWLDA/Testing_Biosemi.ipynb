{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "time : 30.408833980560303\n",
      "[-52.73199735 -18.29860821 -37.56974776  47.28853804 -25.480341\n",
      "  57.10707443 -26.43792758 -29.58603222 -33.5583033   31.37090672\n",
      " -33.56597368  16.77329333  11.4543571  -14.2307663  -14.05465346\n",
      "  -3.55851621   1.40894892  45.34487733 -27.71017425 -34.15921669\n",
      "  14.28234878  61.40979352 -16.84897241 -42.08427656 -15.10151351\n",
      "  16.59806528  54.12236856  44.56335596 -32.67759703   6.58267687\n",
      " -11.01887121  22.08524232 -36.28261673 -36.32793009  33.43797453\n",
      " -28.01609401 -24.8202386  -29.86331869   9.47299716  20.39660808\n",
      "  17.80815069 -17.48436702  -9.83911172 -62.84120169 -12.02542721\n",
      "  48.61013887  15.09107959 -15.04817045 -14.45336507 -21.90851913\n",
      " -29.41781579  52.78302454 -26.22076784 -19.73342995 -23.5513434\n",
      " -23.24516696 -18.47719111 -13.12925108 -14.12140943 -24.85064302\n",
      " -39.93938642  -9.5289143   -2.06342815  -5.00636415  11.01086195\n",
      " -12.43438876 -25.37322934  -7.86288548  -7.76085027 -28.87547886\n",
      " -27.64500342 -21.52307485  38.30995972 -20.28459928 -18.15551932\n",
      "   6.14808448 -17.19224015   7.45683569 -28.5703413  -36.68165268\n",
      " -46.08871817 -30.86744517 -36.99169541 -23.45769789 -13.47992124\n",
      "  46.7399843  -10.89533752 -31.37817452  -0.64745872 -33.42698572\n",
      " -19.9574945  -19.92409596  -3.82455943 -21.49331473  22.29722475\n",
      " -31.186134    19.558542   -33.92741328 -23.21702395 -44.17618266\n",
      " -34.36122913 -30.08206469 -18.87395217 -21.38510771 -25.58532034\n",
      " -20.25881958 -52.10338956  43.78694175  20.9489673  -32.70220782\n",
      " -25.9842966   -3.2581063    7.79612659 -21.88485899 -12.38683828\n",
      " -63.06703132 -27.87216823   3.25864364 -22.28744746 117.20378465]\n",
      "[0 0 0 1 0 1 0 0 0 1 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 1 1 1 0 1 0 1 0 0 1 0 0\n",
      " 0 1 1 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 1 0 0 0 0 1 0 1]\n",
      "decision: 91 / 120\n",
      "predict: 91 / 120\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import hdf5storage\n",
    "import time\n",
    "from scipy import signal\n",
    "from scipy.signal import butter, lfilter\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from datetime import datetime\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "def Re_referencing(eegData, channelNum, sampleNum):\n",
    "        after_car = np.zeros((channelNum,sampleNum))\n",
    "        for i in np.arange(channelNum):\n",
    "            after_car[i,:] = eegData[i,:] - np.mean(eegData,axis=0)\n",
    "        return after_car\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "        nyq = 0.5 * fs\n",
    "        low = lowcut / nyq\n",
    "        high = highcut / nyq\n",
    "        b, a = butter(order, [low, high], btype='band')\n",
    "        return b, a\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "        b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "        y = lfilter(b, a, data)\n",
    "        return y\n",
    "\n",
    "def Standardization(Epochs):\n",
    "    for i in range(Epochs.shape[1]):\n",
    "        Epochs[:,i,:] = np.subtract(Epochs[:,i,:], np.mean(Epochs[:,i,:]))\n",
    "        Epochs[:,i,:] = Epochs[:,i,:] / np.std(Epochs[:,i,:])\n",
    "    \n",
    "    return Epochs \n",
    "\n",
    "def Epoching(eegData, stims, samplingFreq, channelNum, epochSampleNum, offset, baseline):\n",
    "        Time_after = np.add(stims,offset).astype(int)\n",
    "        Time_base = np.add(stims,baseline).astype(int)\n",
    "        Num = stims.shape[1]\n",
    "        Epochs = np.zeros((Num, channelNum, epochSampleNum))\n",
    "        for j in range(Num):\n",
    "            Epochs[j, :, :] = eegData[:,Time_after[0][j]:Time_after[0][j] + epochSampleNum]\n",
    "            \n",
    "            #Baseline Correction\n",
    "            for i in range(Epochs.shape[1]):\n",
    "                Epochs[j,i,:] = Epochs[j,i,:] - np.mean(Epochs[j,i,:])\n",
    "                \n",
    "        return [Epochs,Num]\n",
    "\n",
    "def Make_Average_Component(EpochsT, NumT, EpochsN, NumN, channelNum, epochSampleNum, componentNum):\n",
    "    EpochsT = Standardization(EpochsT)\n",
    "    EpochsN = Standardization(EpochsN)\n",
    "    \n",
    "    NumT_Aver = NumT-componentNum\n",
    "    NumN_Aver = NumN-componentNum\n",
    "    \n",
    "    EpochsT_Aver = np.zeros((NumT_Aver, channelNum, epochSampleNum))\n",
    "    EpochsN_Aver = np.zeros((NumN_Aver, channelNum, epochSampleNum))\n",
    "    \n",
    "    for i in range(NumT_Aver):\n",
    "        EpochsT_Aver[i, :, :] = np.mean(EpochsT[i:i+componentNum, :, :], axis=0)\n",
    "    for j in range(NumN_Aver):\n",
    "        EpochsN_Aver[j, :, :] = np.mean(EpochsN[j:j+componentNum, :, :], axis=0)\n",
    "\n",
    "    return [EpochsT_Aver, NumT_Aver, EpochsN_Aver, NumN_Aver]\n",
    "\n",
    "def resampling(Epochs, EpochNum, resampleRate, channelNum):\n",
    "        resampled_epoch = np.zeros((EpochNum, channelNum, resampleRate))\n",
    "        for i in range(EpochNum):\n",
    "            for j in range(channelNum):\n",
    "                resampled_epoch[i,j,:] = signal.resample(Epochs[i,j,:], resampleRate)\n",
    "                \n",
    "        return resampled_epoch\n",
    "    \n",
    "def Convert_to_featureVector(EpochsT, NumT, EpochsN, NumN, featureNum):\n",
    "        FeaturesT = np.zeros((NumT, featureNum))\n",
    "        for i in range(NumT):\n",
    "            FeaturesT[i,:] = np.reshape(EpochsT[i,:,:],(1,featureNum))\n",
    "        FeaturesN = np.zeros((NumN, featureNum))\n",
    "        for j in range(NumN):\n",
    "            FeaturesN[j,:] = np.reshape(EpochsN[j,:,:],(1,featureNum))\n",
    "        return [FeaturesT,FeaturesN]\n",
    "    \n",
    "def main():\n",
    "    start = time.time()\n",
    "    \n",
    "    root_path = 'C:\\\\Users\\\\hyuns\\\\Desktop\\\\2020-2\\\\캡스톤\\\\EEGData\\\\P300Biosemi55\\\\'\n",
    "    subject = 'S04'\n",
    "    \n",
    "    filename = root_path + subject\n",
    "    \n",
    "    Classifier_path = 'C:\\\\Users\\\\hyuns\\\\Desktop\\\\2020-2\\\\캡스톤\\\\LDAModel\\\\New\\\\' + subject + 'Classifier.pickle'\n",
    "    \n",
    "    channelNum = 32\n",
    "    resampleRate = 128\n",
    "    \n",
    "    target = np.zeros((300,channelNum,resampleRate))\n",
    "    nontarget = np.zeros((300,channelNum,resampleRate))\n",
    "    for i in range(1,3):\n",
    "        if i == 2:\n",
    "            filename = filename + '_2'\n",
    "            \n",
    "        mat = hdf5storage.loadmat(filename)\n",
    "        eegData = mat['eegData']\n",
    "        samplingFreq = mat['samplingFreq'][0,0]\n",
    "        stimsN = mat['stimsN']\n",
    "        stimsT = mat['stimsT']\n",
    "        sampleNum = eegData.shape[1]\n",
    "        \n",
    "        ## Preprocessing process\n",
    "        eegData = Re_referencing(eegData, channelNum, eegData.shape[1])\n",
    "            \n",
    "        #Bandpass Filter\n",
    "        eegData = butter_bandpass_filter(eegData, 0.1, 30, samplingFreq, 4)\n",
    "        \n",
    "        #Epoching\n",
    "        epochSampleNum = int(np.floor(1.0 * samplingFreq))\n",
    "        offset = int(np.floor(0.0 * samplingFreq))\n",
    "        baseline = int(np.floor(1.0 * samplingFreq))\n",
    "        [EpochsT, NumT] = Epoching(eegData, stimsT, samplingFreq, channelNum, epochSampleNum, offset, baseline)\n",
    "        [EpochsN, NumN] = Epoching(eegData, stimsN, samplingFreq, channelNum, epochSampleNum, offset, baseline)\n",
    "        \n",
    "        #Data Balancing\n",
    "        EpochsN_New = np.zeros((NumT, channelNum, epochSampleNum))\n",
    "        NumN = NumT\n",
    "        for j in range(NumN):\n",
    "            EpochsN_New[j,:,:] = np.mean(EpochsN[j*5:j*5+5, :, :], axis=0)\n",
    "        \n",
    "        #Standardization\n",
    "#         EpochsT = Standardization(EpochsT)\n",
    "#         EpochsN = Standardization(EpochsN)\n",
    "        \n",
    "#         [EpochsT, NumT, EpochsN, NumN] = Make_Average_Component(EpochsT, NumT, EpochsN, NumN, channelNum, epochSampleNum, 20)\n",
    "        \n",
    "        #Resampling\n",
    "        EpochsT = resampling(EpochsT, NumT, resampleRate, channelNum) \n",
    "        EpochsN = resampling(EpochsN_New, NumN, resampleRate, channelNum)\n",
    "        \n",
    "        target[150*(i-1):150*i,:,:] = EpochsT\n",
    "        nontarget[150*(i-1):150*i,:,:] = EpochsN\n",
    "    \n",
    "    #Convert to feature vector\n",
    "    featureNum = channelNum*resampleRate\n",
    "    [FeaturesT, FeaturesN] = Convert_to_featureVector(target, 300, nontarget, 300, featureNum)\n",
    "    Data = np.concatenate((FeaturesT, FeaturesN))\n",
    "    Label = np.concatenate((np.ones((300,1)).astype(int),np.zeros((300,1)).astype(int))).ravel()\n",
    "    \n",
    "    s = np.arange(Data.shape[0])\n",
    "    np.random.shuffle(s)\n",
    "    \n",
    "    Data = Data[s]\n",
    "    Label = Label[s]\n",
    "    \n",
    "    TrainData = Data[0:480]\n",
    "    TrainLabel = Label[0:480]\n",
    "    \n",
    "    TestData = Data[480:]\n",
    "    TestLabel = Label[480:]\n",
    "    \n",
    "    #Saving LDA classifier\n",
    "    lda = LinearDiscriminantAnalysis(solver='lsqr',shrinkage='auto')\n",
    "    lda.fit(TrainData, TrainLabel)\n",
    "    joblib.dump(lda, Classifier_path, protocol=2)\n",
    "    \n",
    "    print('Done')\n",
    "    print(\"time :\", time.time() - start)\n",
    "    \n",
    "    model = joblib.load(Classifier_path)\n",
    "    \n",
    "    result = model.decision_function(TestData)\n",
    "    predict = model.predict(TestData)\n",
    "    \n",
    "    print(result)\n",
    "    print(predict)\n",
    "    \n",
    "    decision_score = 0\n",
    "    predict_score = 0\n",
    "    for i in range(len(result)):\n",
    "        if result[i] > 0:\n",
    "            decision = 1\n",
    "        else:\n",
    "            decision = 0\n",
    "        \n",
    "        if TestLabel[i] == decision:\n",
    "            decision_score = decision_score + 1\n",
    "        if TestLabel[i] == predict[i]:\n",
    "            predict_score = predict_score + 1\n",
    "    \n",
    "    print('decision:', decision_score, '/', len(result))\n",
    "    print('predict:', predict_score, '/', len(result))\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "time : 35.34953594207764\n",
      "[ -2.8882325    8.79668112   1.87255926  -9.10893448  -9.41961455\n",
      "   2.06972477  -7.62705075 -11.7084387    4.28734787  -9.57924043\n",
      " -12.08618098  -9.82210188 -14.51469236  -5.65117138  -7.17003216\n",
      " -14.17953053 -16.95264569  -5.98042123  -9.09317976  -9.03170054\n",
      "  -1.51588648  -5.55104514   1.8544442  -22.02439777 -11.51498785\n",
      "  -0.04518944 -17.73707467  -6.71602523  -0.04818083 -11.60121608\n",
      "  -1.40447191 -10.89161105  -8.07579531  -8.01901887  -7.28646233\n",
      "   1.7868999   -6.75682023 -12.75753434  -7.16196504 -11.71851666\n",
      " -10.40388066  -5.69376977  19.49977179  -6.8670501   -3.87003188\n",
      " -16.13005392   7.61095284  -6.72806659   4.3449421   -4.95872102\n",
      "  -1.05523187   1.2876197  -21.6244926   -2.00234262   3.74768456\n",
      "  -1.03349879  -1.9475968    0.99803765   4.0389946  -25.31238049\n",
      "  -3.17362106  -3.16666587 -20.48255581 -10.40993066 -14.89762286\n",
      "  -8.17505177  -9.01077131  -2.14530682  -8.39471439  -3.40111617\n",
      "  -5.27214395 -10.35361325  -0.88910275  -5.36445339  -2.8090252\n",
      " -13.69716122   1.80354788 -11.1191772   -8.86598451 -11.42896375\n",
      "  -3.64753398  -3.79928436 -13.31067537 -12.01448963 -19.03388022\n",
      "  -2.35389875   1.65763287 -17.61781339 -17.13566099 -15.86781164\n",
      "  -6.36197744  -8.24708288   3.35185315  -4.35438656 -17.17010326\n",
      " -12.07001347  -9.67833501  -8.1581127    1.87563382 -22.09224786\n",
      "  -1.21413208  -5.95505993  -3.30274528   9.57324038  -6.91609829\n",
      "  -8.06920038  -6.68235589 -12.09834391  -1.0056326   -2.09891656\n",
      "  -3.24454566 -11.64185916  -4.71520829 -10.50367611  -6.05979119\n",
      "   1.11801699  -9.69309791  -9.25507377 -19.06084232 -27.2750642\n",
      "  -3.7993869   -4.14808911 -16.33446628 -17.13639168  -3.51544966\n",
      "  -9.92499865   6.7171922   -0.31155502  -2.3866104   -3.98456045\n",
      "  -8.17036109 -10.70368952  -7.06730173 -11.54754127 -13.79552483\n",
      "  -5.83434049  -0.95842313 -20.59526072  -7.2299611  -18.59245365\n",
      "  -8.36156727 -24.40301876 -12.80529506  -4.98474793 -15.02148977\n",
      "  -6.3973064   -8.35228936  -8.92749442  -4.84690127  -8.43739639\n",
      " -13.99811505 -24.92858049 -19.64081464  -7.78985555  -7.76860063\n",
      "  -9.20865459   1.57452149   0.24135741  -8.00976047  -5.34840923\n",
      " -24.68250681 -20.69898503   0.3393168   -5.85736121  -4.61539085\n",
      " -10.81373511  -8.2400587   -8.03699137  14.55039019   1.33473652\n",
      "  -8.41521161  -1.38774742   1.56938602 -11.89205673   3.20481162\n",
      " -19.1448835    0.73730001  -9.11696979  -2.85693617 -18.33513024\n",
      "  -6.23845909  -8.54230337 -10.49629846 -19.37078066  -6.1818225\n",
      " -15.81252406 -10.31392101 -17.42070706  -8.51410958  -7.00592229\n",
      "  -5.55426047  -7.87951541  -8.33203097  -6.27333906  -3.19939655\n",
      "   3.73878702 -10.3410586   -1.29133788 -14.79245647  -4.5376878\n",
      " -13.01711703   2.90663213 -14.46242343  -8.18259458   9.12465795\n",
      "  -4.31637553  -4.2302519    2.42105843  -3.32020219 -18.66285867\n",
      " -11.96496368  -3.44665525  -9.13295961  -7.77512207  -7.74430572\n",
      "   7.26752913  -6.46519201   5.49301688   1.57426959  -2.39103067\n",
      " -15.47962379   1.35228499 -11.52038167  -5.09879071  -1.46393284\n",
      "  -9.85168905  -3.38571228 -14.28039213  -8.495431     3.78378335\n",
      " -15.88350615 -10.56132006  -5.05996042  -1.17572708   0.25881411\n",
      "   9.31393904  -8.94519595  -0.49255201  -0.58678671  -5.39224421\n",
      " -12.24932692 -18.86096291  -3.27593764  -6.14528964  -8.64649701\n",
      "   4.12514627 -10.68194353   7.27438671  -1.42090772 -10.37448968\n",
      "  -7.23214308   1.13617597   0.83513683  -5.62081844 -19.49768839\n",
      "   2.28545193 -11.9256017  -10.60188937   7.51467816 -11.51357593\n",
      "  -3.26018915  -1.07572684  -2.10020962  -4.44757912   1.11793522\n",
      "  -4.91847839 -14.2512247  -11.91363098  -9.32324282 -14.87932971\n",
      "  -2.29411853 -15.166951    -5.39782315   1.55775737  -6.39295964\n",
      "  -7.9022691  -10.11736875   1.12615611 -10.13770514 -20.58464343\n",
      "  -9.9532784   -3.29951543  -9.82612653  -5.35936762 -14.33894101\n",
      "   2.96181005  -4.65675527  -0.14877052  -7.2557081   -9.86640736\n",
      "  -6.02255009 -19.31676388 -10.44493193  -7.5286349   -0.54539096\n",
      " -14.07705684  -0.33713495   4.44506822   2.70182624  -8.34826872]\n",
      "[0 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 1\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 1 0 0 1\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 0]\n",
      "decision: 233 / 300\n",
      "predict: 233 / 300\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import hdf5storage\n",
    "import time\n",
    "from scipy import signal\n",
    "from scipy.signal import butter, lfilter\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from datetime import datetime\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "def Re_referencing(eegData, channelNum, sampleNum):\n",
    "        after_car = np.zeros((channelNum,sampleNum))\n",
    "        for i in np.arange(channelNum):\n",
    "            after_car[i,:] = eegData[i,:] - np.mean(eegData,axis=0)\n",
    "        return after_car\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "        nyq = 0.5 * fs\n",
    "        low = lowcut / nyq\n",
    "        high = highcut / nyq\n",
    "        b, a = butter(order, [low, high], btype='band')\n",
    "        return b, a\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "        b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "        y = lfilter(b, a, data)\n",
    "        return y\n",
    "\n",
    "def Standardization(Epochs):\n",
    "    for i in range(Epochs.shape[1]):\n",
    "        Epochs[:,i,:] = np.subtract(Epochs[:,i,:], np.mean(Epochs[:,i,:]))\n",
    "        Epochs[:,i,:] = Epochs[:,i,:] / np.std(Epochs[:,i,:])\n",
    "    \n",
    "    return Epochs \n",
    "\n",
    "def Epoching(eegData, stims, samplingFreq, channelNum, epochSampleNum, offset, baseline):\n",
    "        Time_after = np.add(stims,offset).astype(int)\n",
    "        Time_base = np.add(stims,baseline).astype(int)\n",
    "        Num = stims.shape[1]\n",
    "        Epochs = np.zeros((Num, channelNum, epochSampleNum))\n",
    "        for j in range(Num):\n",
    "            Epochs[j, :, :] = eegData[:,Time_after[0][j]:Time_after[0][j] + epochSampleNum]\n",
    "            \n",
    "            #Baseline Correction\n",
    "            for i in range(Epochs.shape[1]):\n",
    "                Epochs[j,i,:] = Epochs[j,i,:] - np.mean(Epochs[j,i,:])\n",
    "                \n",
    "        return [Epochs,Num]\n",
    "\n",
    "def Make_Average_Component(EpochsT, NumT, EpochsN, NumN, channelNum, epochSampleNum, componentNum):\n",
    "    EpochsT = Standardization(EpochsT)\n",
    "    EpochsN = Standardization(EpochsN)\n",
    "    \n",
    "    NumT_Aver = NumT-componentNum\n",
    "    NumN_Aver = NumN-componentNum\n",
    "    \n",
    "    EpochsT_Aver = np.zeros((NumT_Aver, channelNum, epochSampleNum))\n",
    "    EpochsN_Aver = np.zeros((NumN_Aver, channelNum, epochSampleNum))\n",
    "    \n",
    "    for i in range(NumT_Aver):\n",
    "        EpochsT_Aver[i, :, :] = np.mean(EpochsT[i:i+componentNum, :, :], axis=0)\n",
    "    for j in range(NumN_Aver):\n",
    "        EpochsN_Aver[j, :, :] = np.mean(EpochsN[j:j+componentNum, :, :], axis=0)\n",
    "\n",
    "    return [EpochsT_Aver, NumT_Aver, EpochsN_Aver, NumN_Aver]\n",
    "\n",
    "def resampling(Epochs, EpochNum, resampleRate, channelNum):\n",
    "        resampled_epoch = np.zeros((EpochNum, channelNum, resampleRate))\n",
    "        for i in range(EpochNum):\n",
    "            for j in range(channelNum):\n",
    "                resampled_epoch[i,j,:] = signal.resample(Epochs[i,j,:], resampleRate)\n",
    "                \n",
    "        return resampled_epoch\n",
    "    \n",
    "def Convert_to_featureVector(EpochsT, NumT, EpochsN, NumN, featureNum):\n",
    "        FeaturesT = np.zeros((NumT, featureNum))\n",
    "        for i in range(NumT):\n",
    "            FeaturesT[i,:] = np.reshape(EpochsT[i,:,:],(1,featureNum))\n",
    "        FeaturesN = np.zeros((NumN, featureNum))\n",
    "        for j in range(NumN):\n",
    "            FeaturesN[j,:] = np.reshape(EpochsN[j,:,:],(1,featureNum))\n",
    "        return [FeaturesT,FeaturesN]\n",
    "    \n",
    "def main():\n",
    "    start = time.time()\n",
    "    \n",
    "    root_path = 'C:\\\\Users\\\\hyuns\\\\Desktop\\\\2020-2\\\\캡스톤\\\\EEGData\\\\P300Biosemi55\\\\'\n",
    "    subject = 'S04'\n",
    "    \n",
    "    filename = root_path + subject\n",
    "    \n",
    "    Classifier_path = 'C:\\\\Users\\\\hyuns\\\\Desktop\\\\2020-2\\\\캡스톤\\\\LDAModel\\\\New\\\\' + subject + 'Classifier.pickle'\n",
    "    \n",
    "    channelNum = 32\n",
    "    resampleRate = 128\n",
    "    \n",
    "    target = np.zeros((300,channelNum,resampleRate))\n",
    "    nontarget = np.zeros((1500,channelNum,resampleRate))\n",
    "    for i in range(1,3):\n",
    "        if i == 2:\n",
    "            filename = filename + '_2'\n",
    "            \n",
    "        mat = hdf5storage.loadmat(filename)\n",
    "        eegData = mat['eegData']\n",
    "        samplingFreq = mat['samplingFreq'][0,0]\n",
    "        stimsN = mat['stimsN']\n",
    "        stimsT = mat['stimsT']\n",
    "        sampleNum = eegData.shape[1]\n",
    "        \n",
    "        ## Preprocessing process\n",
    "        eegData = Re_referencing(eegData, channelNum, eegData.shape[1])\n",
    "            \n",
    "        #Bandpass Filter\n",
    "        eegData = butter_bandpass_filter(eegData, 0.1, 30, samplingFreq, 4)\n",
    "        \n",
    "        #Epoching\n",
    "        epochSampleNum = int(np.floor(1.0 * samplingFreq))\n",
    "        offset = int(np.floor(0.0 * samplingFreq))\n",
    "        baseline = int(np.floor(1.0 * samplingFreq))\n",
    "        [EpochsT, NumT] = Epoching(eegData, stimsT, samplingFreq, channelNum, epochSampleNum, offset, baseline)\n",
    "        [EpochsN, NumN] = Epoching(eegData, stimsN, samplingFreq, channelNum, epochSampleNum, offset, baseline)\n",
    "        \n",
    "        #Data Balancing\n",
    "#         EpochsN_New = np.zeros((NumT, channelNum, epochSampleNum))\n",
    "#         NumN = NumT\n",
    "#         for j in range(NumN):\n",
    "#             EpochsN_New[j,:,:] = np.mean(EpochsN[j*5:j*5+5, :, :], axis=0)\n",
    "        \n",
    "        #Standardization\n",
    "#         EpochsT = Standardization(EpochsT)\n",
    "#         EpochsN = Standardization(EpochsN)\n",
    "        \n",
    "#         [EpochsT, NumT, EpochsN, NumN] = Make_Average_Component(EpochsT, NumT, EpochsN, NumN, channelNum, epochSampleNum, 20)\n",
    "        \n",
    "        #Resampling\n",
    "        EpochsT = resampling(EpochsT, NumT, resampleRate, channelNum) \n",
    "        EpochsN = resampling(EpochsN, NumN, resampleRate, channelNum)\n",
    "        \n",
    "        target[150*(i-1):150*i,:,:] = EpochsT\n",
    "        nontarget[750*(i-1):750*i,:,:] = EpochsN\n",
    "    \n",
    "    #Convert to feature vector\n",
    "    featureNum = channelNum*resampleRate\n",
    "    [FeaturesT, FeaturesN] = Convert_to_featureVector(target, 300, nontarget, 1500, featureNum)\n",
    "    Data = np.concatenate((FeaturesT, FeaturesN))\n",
    "    Label = np.concatenate((np.ones((300,1)).astype(int),np.zeros((1500,1)).astype(int))).ravel()\n",
    "    \n",
    "    s = np.arange(Data.shape[0])\n",
    "    np.random.shuffle(s)\n",
    "    \n",
    "    Data = Data[s]\n",
    "    Label = Label[s]\n",
    "    \n",
    "    TrainData = Data[0:1500]\n",
    "    TrainLabel = Label[0:1500]\n",
    "    \n",
    "    TestData = Data[1500:]\n",
    "    TestLabel = Label[1500:]\n",
    "    \n",
    "    #Saving LDA classifier\n",
    "    lda = LinearDiscriminantAnalysis(solver='lsqr',shrinkage='auto')\n",
    "    lda.fit(TrainData, TrainLabel)\n",
    "    joblib.dump(lda, Classifier_path, protocol=2)\n",
    "    \n",
    "    print('Done')\n",
    "    print(\"time :\", time.time() - start)\n",
    "    \n",
    "    model = joblib.load(Classifier_path)\n",
    "    \n",
    "    result = model.decision_function(TestData)\n",
    "    predict = model.predict(TestData)\n",
    "    \n",
    "    print(result)\n",
    "    print(predict)\n",
    "    \n",
    "    decision_score = 0\n",
    "    predict_score = 0\n",
    "    for i in range(len(result)):\n",
    "        if result[i] > 0:\n",
    "            decision = 1\n",
    "        else:\n",
    "            decision = 0\n",
    "        \n",
    "        if TestLabel[i] == decision:\n",
    "            decision_score = decision_score + 1\n",
    "        if TestLabel[i] == predict[i]:\n",
    "            predict_score = predict_score + 1\n",
    "    \n",
    "    print('decision:', decision_score, '/', len(result))\n",
    "    print('predict:', predict_score, '/', len(result))\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
