{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/sy/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumT : 210\n",
      "NumN : 1260\n",
      "time : 0.5763671398162842\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import hdf5storage\n",
    "from scipy.signal import butter, lfilter\n",
    "import os, glob, time\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from datetime import datetime\n",
    "from sklearn.externals import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def Re_referencing(eegData, channelNum, sampleNum):\n",
    "        after_car = np.zeros((channelNum,sampleNum))\n",
    "        for i in np.arange(channelNum):\n",
    "            after_car[i,:] = eegData[i,:] - np.mean(eegData,axis=0)\n",
    "        return after_car\n",
    "    \n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "        nyq = 0.5 * fs\n",
    "        low = lowcut / nyq\n",
    "        high = highcut / nyq\n",
    "        b, a = butter(order, [low, high], btype='band')\n",
    "        return b, a\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "        b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "        y = lfilter(b, a, data)\n",
    "        return y\n",
    "\n",
    "def Epoching(eegData, stims, code, samplingRate, nChannel, epochSampleNum, epochOffset,baseline):\n",
    "        Time = stims[np.where(stims[:,1] == code),0][0]\n",
    "        Time = np.floor(np.multiply(Time,samplingRate)).astype(int)\n",
    "        Time_after = np.add(Time,epochOffset).astype(int)\n",
    "        Time_base = np.add(Time,baseline).astype(int)\n",
    "        Num = Time.shape\n",
    "        Epochs = np.zeros((Num[0], nChannel, epochSampleNum))\n",
    "        for j in range(Num[0]):\n",
    "            Epochs[j, :, :] = eegData[:, Time_after[j]:Time_after[j] + epochSampleNum]\n",
    "            for i in range(nChannel):\n",
    "                Epochs[j, i, :] = np.subtract(Epochs[j, i, :], np.mean(eegData[i,Time_after[j]:Time_base[j]]))\n",
    "        return [Epochs, Num[0]]\n",
    "\n",
    "def Convert_to_featureVector(EpochsT, NumT, EpochsN, NumN, featureNum):\n",
    "        FeaturesT = np.zeros((NumT, featureNum))\n",
    "        for i in range(NumT):\n",
    "            FeaturesT[i,:] = np.reshape(EpochsT[i,:,:],(1,featureNum))\n",
    "        FeaturesN = np.zeros((NumN, featureNum))\n",
    "        for j in range(NumN):\n",
    "            FeaturesN[j,:] = np.reshape(EpochsN[j,:,:],(1,featureNum))\n",
    "        return [FeaturesT,FeaturesN] \n",
    "    \n",
    "def main():\n",
    "        start = time.time()\n",
    "        \n",
    "        ##Generate Preprocessing Training data\n",
    "        ctime = datetime.today().strftime(\"%m%d_%H%M\")\n",
    "        Classifier_path = '/Users/hyuns/Desktop/LDAModel/' + ctime + 'Classifier.pickle'\n",
    "        channelNum = 7\n",
    "\n",
    "        mat_path = root_path + 'Training/'\n",
    "        current_list = sorted(glob.glob(mat_path + '*.mat'), key=os.path.getmtime)\n",
    "        \n",
    "        matfile_name = current_list[0]\n",
    "        \n",
    "        mat = hdf5storage.loadmat(matfile_name)\n",
    "        channelNames = mat['channelNames']\n",
    "        eegData = mat['eegData']\n",
    "        samplingFreq = mat['samplingFreq']\n",
    "        samplingFreq = samplingFreq[0,0]\n",
    "        stims = mat['stims']\n",
    "        channelNum = channelNames.shape\n",
    "        channelNum = channelNum[1]\n",
    "        eegData = np.transpose(eegData)\n",
    "        \n",
    "        ##Preprocessing process\n",
    "        sampleNum = eegData.shape[1]\n",
    "        \n",
    "        #Common Average Reference\n",
    "        eegData = Re_referencing(eegData, channelNum, sampleNum)\n",
    "\n",
    "        #Bandpass Filter\n",
    "        eegData = butter_bandpass_filter(eegData, 0.5, 10, samplingFreq, order=4)\n",
    "    \n",
    "        #Epoching\n",
    "        epochSampleNum = int(np.floor(0.4 * samplingFreq))\n",
    "        offset = int(np.floor(0.2 * samplingFreq)) \n",
    "        baseline = int(np.floor(0.6 * samplingFreq)) \n",
    "        [EpochsT, NumT] = Epoching(eegData, stims, 1, samplingFreq, channelNum, epochSampleNum, offset, baseline)\n",
    "        [EpochsN, NumN] = Epoching(eegData, stims, 0, samplingFreq, channelNum, epochSampleNum, offset, baseline)\n",
    "        \n",
    "        #Convert to feature vector\n",
    "        featureNum = channelNum*epochSampleNum\n",
    "        [FeaturesT, FeaturesN] = Convert_to_featureVector(EpochsT, NumT, EpochsN, NumN, featureNum)\n",
    "        TrainData = np.concatenate((FeaturesT, FeaturesN))\n",
    "        TrainLabel = np.concatenate((np.ones((NumT,1)).astype(int),np.zeros((NumN ,1)).astype(int))).ravel()\n",
    "        \n",
    "        #Saving LDA classifier\n",
    "        lda = LinearDiscriminantAnalysis(solver='lsqr',shrinkage='auto')\n",
    "        lda.fit(TrainData, TrainLabel)\n",
    "        joblib.dump(lda, Classifier_path, protocol=2)\n",
    "        \n",
    "        print(\"NumT :\", NumT)\n",
    "        print(\"NumN :\", NumN)\n",
    "        print(\"time :\", time.time() - start)\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifer: /Users/hyuns/Desktop/LDAModel/0811_1350Classifier.pickle\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/sy/Online/1_3.mat\n",
      "[[0. 0. 0. 0. 0. 0. 0.]]\n",
      "order:  3 predict:  1\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/sy/Online/2_7.mat\n",
      "[[0. 0. 0. 0. 0. 0. 0.]]\n",
      "order:  7 predict:  1\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/sy/Online/3_1.mat\n",
      "[[0. 0. 0. 0. 0. 0. 0.]]\n",
      "order:  1 predict:  1\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/sy/Online/4_2.mat\n",
      "[[1. 1. 0. 0. 0. 0. 1.]]\n",
      "order:  2 predict:  1\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/sy/Online/5_5.mat\n",
      "[[0. 0. 0. 0. 0. 0. 0.]]\n",
      "order:  5 predict:  1\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/sy/Online/6_3.mat\n",
      "[[1. 1. 0. 0. 0. 0. 0.]]\n",
      "order:  3 predict:  1\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/sy/Online/7_3.mat\n",
      "[[0. 0. 0. 0. 0. 0. 0.]]\n",
      "order:  3 predict:  1\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/sy/Online/8_1.mat\n",
      "[[0. 0. 0. 0. 0. 0. 0.]]\n",
      "order:  1 predict:  1\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/sy/Online/9_1.mat\n",
      "[[0. 0. 0. 0. 0. 0. 0.]]\n",
      "order:  1 predict:  1\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/sy/Online/10_2.mat\n",
      "[[0. 0. 0. 0. 0. 0. 0.]]\n",
      "order:  2 predict:  1\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/sy/Online/11_2.mat\n",
      "[[1. 0. 2. 0. 3. 1. 1.]]\n",
      "order:  2 predict:  5\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/sy/Online/12_1.mat\n",
      "[[2. 2. 3. 0. 1. 3. 1.]]\n",
      "order:  1 predict:  3\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/sy/Online/13_1.mat\n",
      "[[0. 0. 0. 0. 0. 1. 0.]]\n",
      "order:  1 predict:  6\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/sy/Online/14_5.mat\n",
      "[[1. 1. 1. 2. 0. 1. 0.]]\n",
      "order:  5 predict:  4\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/sy/Online/15_5.mat\n",
      "[[0. 2. 1. 2. 2. 1. 1.]]\n",
      "order:  5 predict:  2\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/sy/Online/16_2.mat\n",
      "[[0. 0. 1. 2. 1. 0. 2.]]\n",
      "order:  2 predict:  4\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/sy/Online/17_1.mat\n",
      "[[0. 1. 1. 0. 0. 1. 0.]]\n",
      "order:  1 predict:  2\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/sy/Online/18_1.mat\n",
      "[[1. 0. 0. 0. 1. 0. 0.]]\n",
      "order:  1 predict:  1\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/sy/Online/19_5.mat\n",
      "[[1. 0. 1. 1. 0. 1. 2.]]\n",
      "order:  5 predict:  7\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/sy/Online/20_5.mat\n",
      "[[0. 0. 0. 0. 0. 0. 0.]]\n",
      "order:  5 predict:  1\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/sy/Online/21_3.mat\n",
      "[[0. 0. 0. 0. 0. 0. 0.]]\n",
      "order:  3 predict:  1\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/sy/Online/22_7.mat\n",
      "[[1. 0. 0. 0. 0. 0. 1.]]\n",
      "order:  7 predict:  1\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/sy/Online/23_1.mat\n",
      "[[0. 0. 0. 0. 0. 0. 0.]]\n",
      "order:  1 predict:  1\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/sy/Online/24_2.mat\n",
      "[[0. 0. 0. 0. 0. 0. 0.]]\n",
      "order:  2 predict:  1\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/sy/Online/25_5.mat\n",
      "[[0. 0. 0. 0. 0. 0. 0.]]\n",
      "order:  5 predict:  1\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/sy/Online/26_5.mat\n",
      "[[1. 0. 0. 0. 0. 1. 2.]]\n",
      "order:  5 predict:  7\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/sy/Online/27_2.mat\n",
      "[[3. 1. 2. 1. 1. 1. 0.]]\n",
      "order:  2 predict:  1\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/sy/Online/28_1.mat\n",
      "[[9. 2. 4. 3. 5. 4. 3.]]\n",
      "order:  1 predict:  1\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/sy/Online/29_3.mat\n",
      "[[4. 5. 1. 2. 2. 4. 5.]]\n",
      "order:  3 predict:  2\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/sy/Online/30_7.mat\n",
      "[[3. 4. 2. 0. 4. 3. 1.]]\n",
      "order:  7 predict:  2\n",
      "score: 6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import butter, lfilter, sosfiltfilt\n",
    "import time\n",
    "import os, glob\n",
    "import hdf5storage\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.externals import joblib\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import socket\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def Re_referencing(eegData, channelNum, sampleNum):\n",
    "        after_car = np.zeros((channelNum,sampleNum))\n",
    "        for i in np.arange(channelNum):\n",
    "            after_car[i,:] = eegData[i,:] - np.mean(eegData,axis=0)\n",
    "        return after_car\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "        nyq = 0.5 * fs\n",
    "        low = lowcut / nyq\n",
    "        high = highcut / nyq\n",
    "        b, a = butter(order, [low, high], btype='band')\n",
    "        return b, a\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "        b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "        y = lfilter(b, a, data)\n",
    "        return y   \n",
    "    \n",
    "def Epoching(eegData, stims, code, samplingRate, nChannel, epochSampleNum, epochOffset,baseline):\n",
    "        Time = stims[np.where(stims[:,1] == code),0][0]\n",
    "        Time = np.floor(np.multiply(Time,samplingRate)).astype(int)\n",
    "        Time_after = np.add(Time,epochOffset).astype(int)\n",
    "        Time_base = np.add(Time,baseline).astype(int)\n",
    "        Num = Time.shape\n",
    "        Epochs = np.zeros((Num[0], nChannel, epochSampleNum))\n",
    "        for j in range(Num[0]):\n",
    "            Epochs[j, :, :] = eegData[:, Time_after[j]:Time_after[j] + epochSampleNum]\n",
    "            for i in range(nChannel):\n",
    "                Epochs[j, i, :] = np.subtract(Epochs[j, i, :], np.mean(eegData[i,Time_after[j]:Time_base[j]]))\n",
    "        \n",
    "        return [Epochs, Num[0]]\n",
    "\n",
    "def Online_Convert_to_featureVector2(Epochs, Num, featureNum):\n",
    "    Features = np.zeros((Num, featureNum))\n",
    "    \n",
    "    for i in range(Num):\n",
    "        Features[i,:] = np.reshape(Epochs[i,:,:], (1, featureNum))\n",
    "    return Features\n",
    "\n",
    "\n",
    "def main():\n",
    "        Classifier_path = '/Users/hyuns/Desktop/LDAModel/'\n",
    "        classifier_list = sorted(glob.glob(Classifier_path + '*.pickle'), key=os.path.getmtime, reverse=True)\n",
    "        print(\"classifer:\", classifier_list[0])\n",
    "        \n",
    "        lda = joblib.load(classifier_list[0])\n",
    "        \n",
    "        mat_path = root_path + 'Online/'\n",
    "        current_list = sorted(glob.glob(mat_path + '*.mat'), key=os.path.getmtime, reverse=True)\n",
    "        score = 0\n",
    "        \n",
    "        for mat_file in current_list:\n",
    "            print(mat_file)\n",
    "            ans = mat_file[-5]\n",
    "            \n",
    "            mat = hdf5storage.loadmat(mat_file)\n",
    "            channelNames = mat['channelNames']\n",
    "            eegData = mat['eegData']\n",
    "            samplingFreq = mat['samplingFreq']\n",
    "            samplingFreq = samplingFreq[0,0]\n",
    "            stims = mat['stims']\n",
    "            channelNum = channelNames.shape\n",
    "            channelNum = channelNum[1]\n",
    "            eegData = np.transpose(eegData)\n",
    "            buttonNum = 7\n",
    "            \n",
    "            sampleNum = eegData.shape[1]\n",
    "            #Common Average Reference\n",
    "            eegData = Re_referencing(eegData, channelNum, sampleNum)\n",
    "            \n",
    "            #Bandpass Filter\n",
    "            eegData = butter_bandpass_filter(eegData, 0.5, 10, samplingFreq, order=4)\n",
    "\n",
    "            #Epoching\n",
    "            epochSampleNum = int(np.floor(0.4 * samplingFreq))\n",
    "            offset = int(np.floor(0.2 * samplingFreq)) \n",
    "            baseline = int(np.floor(0.6 * samplingFreq)) \n",
    "            [Epochs1, Num1] = Epoching(eegData, stims, 1, samplingFreq, channelNum, epochSampleNum, offset, baseline)\n",
    "            [Epochs2, Num2] = Epoching(eegData, stims, 2, samplingFreq, channelNum, epochSampleNum, offset, baseline)\n",
    "            [Epochs3, Num3] = Epoching(eegData, stims, 3, samplingFreq, channelNum, epochSampleNum, offset, baseline)\n",
    "            [Epochs4, Num4] = Epoching(eegData, stims, 4, samplingFreq, channelNum, epochSampleNum, offset, baseline)\n",
    "            [Epochs5, Num5] = Epoching(eegData, stims, 5, samplingFreq, channelNum, epochSampleNum, offset, baseline)\n",
    "            [Epochs6, Num6] = Epoching(eegData, stims, 6, samplingFreq, channelNum, epochSampleNum, offset, baseline)\n",
    "            [Epochs7, Num7] = Epoching(eegData, stims, 7, samplingFreq, channelNum, epochSampleNum, offset, baseline)\n",
    "            \n",
    "            result = np.zeros((1,buttonNum))\n",
    "            featureNum = channelNum*epochSampleNum\n",
    "            \n",
    "            Epochs1 = Online_Convert_to_featureVector2(Epochs1, Num1, featureNum)\n",
    "            Epochs2 = Online_Convert_to_featureVector2(Epochs2, Num1, featureNum)\n",
    "            Epochs3 = Online_Convert_to_featureVector2(Epochs3, Num1, featureNum)\n",
    "            Epochs4 = Online_Convert_to_featureVector2(Epochs4, Num1, featureNum)\n",
    "            Epochs5 = Online_Convert_to_featureVector2(Epochs5, Num1, featureNum)\n",
    "            Epochs6 = Online_Convert_to_featureVector2(Epochs6, Num1, featureNum)\n",
    "            Epochs7 = Online_Convert_to_featureVector2(Epochs7, Num1, featureNum)\n",
    "            \n",
    "            a1 = lda.predict(Epochs1)\n",
    "            a2 = lda.predict(Epochs2)\n",
    "            a3 = lda.predict(Epochs3)\n",
    "            a4 = lda.predict(Epochs4)\n",
    "            a5 = lda.predict(Epochs5)\n",
    "            a6 = lda.predict(Epochs6)\n",
    "            a7 = lda.predict(Epochs7)\n",
    "\n",
    "            result[0,0] = np.sum(a1)\n",
    "            result[0,1] = np.sum(a2)\n",
    "            result[0,2] = np.sum(a3)\n",
    "            result[0,3] = np.sum(a4)\n",
    "            result[0,4] = np.sum(a5)\n",
    "            result[0,5] = np.sum(a6)\n",
    "            result[0,6] = np.sum(a7)\n",
    "            \n",
    "            answer = np.argmax(result) + 1\n",
    "            if int(ans) == int(answer): \n",
    "                score = score + 1\n",
    "            \n",
    "            print(result)\n",
    "            print('order: ', ans, 'predict: ', answer)\n",
    "        \n",
    "        print('score:', score)\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
