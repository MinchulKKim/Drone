{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumT : 210\n",
      "NumT_Aver : 190\n",
      "NumN_Aver : 190\n",
      "time : 2.3462789058685303\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import hdf5storage\n",
    "from scipy.signal import butter, lfilter\n",
    "import os, glob, time\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from datetime import datetime\n",
    "from sklearn.externals import joblib\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "    \n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "        nyq = 0.5 * fs\n",
    "        low = lowcut / nyq\n",
    "        high = highcut / nyq\n",
    "        b, a = butter(order, [low, high], btype='band')\n",
    "        return b, a\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "        b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "        y = lfilter(b, a, data)\n",
    "        return y\n",
    "\n",
    "def Epoching(eegData, stims, code, samplingRate, nChannel, epochSampleNum, epochOffset,baseline):\n",
    "        Time = stims[np.where(stims[:,1] == code),0][0]\n",
    "        Time = np.floor(np.multiply(Time,samplingRate)).astype(int)\n",
    "        Time_after = np.add(Time,epochOffset).astype(int)\n",
    "        Time_base = np.add(Time,baseline).astype(int)\n",
    "        Num = Time.shape\n",
    "        Epochs = np.zeros((Num[0], nChannel, epochSampleNum))\n",
    "        for j in range(Num[0]):\n",
    "            Epochs[j, :, :] = eegData[:, Time_after[j]:Time_after[j] + epochSampleNum]\n",
    "            \n",
    "        return [Epochs, Num[0]]\n",
    "\n",
    "def Convert_to_featureVector(EpochsT, NumT, EpochsN, NumN, featureNum):\n",
    "        FeaturesT = np.zeros((NumT, featureNum))\n",
    "        for i in range(NumT):\n",
    "            FeaturesT[i,:] = np.reshape(EpochsT[i,:,:],(1,featureNum))\n",
    "        FeaturesN = np.zeros((NumN, featureNum))\n",
    "        for j in range(NumN):\n",
    "            FeaturesN[j,:] = np.reshape(EpochsN[j,:,:],(1,featureNum))\n",
    "        return [FeaturesT,FeaturesN]\n",
    "\n",
    "def Balancing_DataSet(Epochs, size):\n",
    "    Epochs_New = np.zeros((size, Epochs.shape[1], Epochs.shape[2]))\n",
    "    \n",
    "    index = np.random.choice(Epochs.shape[0], size = size, replace = False)\n",
    "    \n",
    "    Epochs_New = Epochs[index, :, :]\n",
    "    \n",
    "    return Epochs_New\n",
    "    \n",
    "def Standardization(Epochs):\n",
    "    for i in range(Epochs.shape[1]):\n",
    "        Epochs[:,i,:] = np.subtract(Epochs[:,i,:], np.mean(Epochs[:,i,:]))\n",
    "        Epochs[:,i,:] = Epochs[:,i,:] / np.std(Epochs[:,i,:])\n",
    "    \n",
    "    return Epochs\n",
    "\n",
    "def Make_Average_Component(EpochsT, NumT, EpochsN, NumN, channelNum, epochSampleNum, componentNum):\n",
    "    EpochsT = Standardization(EpochsT)\n",
    "    EpochsN = Standardization(EpochsN)\n",
    "    \n",
    "    NumT_Aver = NumT-componentNum\n",
    "    NumN_Aver = NumN-componentNum\n",
    "    \n",
    "    EpochsT_Aver = np.zeros((NumT_Aver, channelNum, epochSampleNum))\n",
    "    EpochsN_Aver = np.zeros((NumN_Aver, channelNum, epochSampleNum))\n",
    "    for i in range(NumT_Aver):\n",
    "        EpochsT_Aver[i, :, :] = np.mean(EpochsT[i:i+componentNum, :, :], axis=0)\n",
    "    for j in range(NumN_Aver):\n",
    "        EpochsN_Aver[j, :, :] = np.mean(EpochsN[j:j+componentNum, :, :], axis=0)\n",
    "        \n",
    "    return [EpochsT_Aver, NumT_Aver, EpochsN_Aver, NumN_Aver]\n",
    "    \n",
    "def main():\n",
    "        start = time.time()\n",
    "        \n",
    "        ##Generate Preprocessing Training data\n",
    "        ctime = datetime.today().strftime(\"%m%d_%H%M\")\n",
    "        Classifier_path = '/Users/hyuns/Desktop/LDAModel/' + ctime + 'Classifier.pickle'\n",
    "        channelNum = 7\n",
    "        \n",
    "        mat_path = root_path + 'Training/'\n",
    "        current_list = sorted(glob.glob(mat_path + '*.mat'), key=os.path.getmtime)\n",
    "        \n",
    "        matfile_name = current_list[0]\n",
    "        \n",
    "        mat = hdf5storage.loadmat(matfile_name)\n",
    "        channelNames = mat['channelNames']\n",
    "        eegData = mat['eegData']\n",
    "        samplingFreq = mat['samplingFreq']\n",
    "        samplingFreq = samplingFreq[0,0]\n",
    "        stims = mat['stims']\n",
    "        channelNum = channelNames.shape\n",
    "        channelNum = channelNum[1]\n",
    "        eegData = np.transpose(eegData)\n",
    "        \n",
    "        ##Preprocessing process\n",
    "        sampleNum = eegData.shape[1]\n",
    "\n",
    "        #Bandpass Filter\n",
    "        eegData = butter_bandpass_filter(eegData, 0.1, 30, samplingFreq, order=4)\n",
    "    \n",
    "        #Epoching\n",
    "        epochSampleNum = int(np.floor(1.0 * samplingFreq))\n",
    "        offset = int(np.floor(0.0 * samplingFreq)) \n",
    "        baseline = int(np.floor(1.0 * samplingFreq)) \n",
    "        [EpochsT, NumT] = Epoching(eegData, stims, 1, samplingFreq, channelNum, epochSampleNum, offset, baseline)\n",
    "        [EpochsN, NumN] = Epoching(eegData, stims, 0, samplingFreq, channelNum, epochSampleNum, offset, baseline)\n",
    "        \n",
    "        NumN = NumT\n",
    "        EpochsN_New = Balancing_DataSet(EpochsN, NumN)\n",
    "        \n",
    "        #Convert to feature vector\n",
    "        [EpochsT_Aver, NumT_Aver, EpochsN_Aver, NumN_Aver] = Make_Average_Component(EpochsT, NumT, EpochsN_New, NumN, channelNum, epochSampleNum, 20)\n",
    "        \n",
    "        featureNum = channelNum*epochSampleNum\n",
    "        \n",
    "        [FeaturesT, FeaturesN] = Convert_to_featureVector(EpochsT_Aver, NumT_Aver, EpochsN_Aver, NumN_Aver, featureNum)\n",
    "        TrainData = np.concatenate((FeaturesT, FeaturesN))\n",
    "        TrainLabel = np.concatenate((np.ones((NumT_Aver,1)).astype(int),np.zeros((NumN_Aver,1)).astype(int))).ravel()\n",
    "        \n",
    "        #Saving LDA classifier\n",
    "        lda = LinearDiscriminantAnalysis(solver='lsqr',shrinkage='auto')\n",
    "        lda.fit(TrainData, TrainLabel)\n",
    "        joblib.dump(lda, Classifier_path, protocol=2)\n",
    "        \n",
    "        print(\"NumT :\", NumT)\n",
    "        print(\"NumT_Aver :\", NumT_Aver)\n",
    "        print(\"NumN_Aver :\", NumN_Aver)\n",
    "        print(\"time :\", time.time() - start)\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifer: /Users/hyuns/Desktop/LDAModel/0803_1052Classifier.pickle\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/1_2.mat\n",
      "[   10.63265034  1061.96613439 -1238.700827    -819.58518735\n",
      "  -853.36224125  -632.42317094   136.07007108]\n",
      "order:  2 predict:  2\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/2_4.mat\n",
      "[ -607.55806185  -778.05959263  -265.75305457     9.77563682\n",
      "  -308.77269893 -1002.06219051  -419.81768195]\n",
      "order:  4 predict:  4\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/3_6.mat\n",
      "[-185.78610027 -461.70371684 -396.72970583 -474.14384361 -713.7400943\n",
      "  631.05502756 -379.33912164]\n",
      "order:  6 predict:  6\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/4_1.mat\n",
      "[ 426.37940132 -351.30991608 -618.1613359  -471.95620778 -484.36963073\n",
      " -446.07938206 -579.38817102]\n",
      "order:  1 predict:  1\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/5_3.mat\n",
      "[-776.9919337  -266.05945373  326.93702012 -727.66711933 -479.21219301\n",
      " -626.35704479 -608.38863394]\n",
      "order:  3 predict:  3\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/6_7.mat\n",
      "[-940.98111427 -716.62333197 -431.35164673 -523.88225241 -473.79669756\n",
      " -425.61291822  906.66498012]\n",
      "order:  7 predict:  7\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/7_1.mat\n",
      "[ 1038.3604363   -461.0627091   -487.68786891 -1357.89350996\n",
      "  -153.92147106  -318.3836666   -756.21424254]\n",
      "order:  1 predict:  1\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/8_2.mat\n",
      "[ -115.11019588  1719.42428517  -717.10553543  -854.65058151\n",
      " -1112.40249292  -505.07675099  -581.37632581]\n",
      "order:  2 predict:  2\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/9_5.mat\n",
      "[ -71.91680299 -793.52742205 -303.54388298 -679.36790749  735.58062666\n",
      " -443.38045358 -955.80345032]\n",
      "order:  5 predict:  5\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/10_6.mat\n",
      "[-1319.37219647  -499.65443616  -526.25545642  -613.1762655\n",
      "  -450.66333424  1217.42691015  -143.75844276]\n",
      "order:  6 predict:  6\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/11_7.mat\n",
      "[-693.47220303 -656.6680961  -289.08677532 -756.22567026 -575.45385322\n",
      " -256.62084863  582.67470052]\n",
      "order:  7 predict:  7\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/12_1.mat\n",
      "[ 1252.07437259  -869.62006142  -668.30927872 -1422.00587573\n",
      "  -320.30210715  -843.93505682  -484.54835055]\n",
      "order:  1 predict:  1\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/13_5.mat\n",
      "[-961.03861834 -910.54560879 -465.15114735 -553.53386176  844.68195478\n",
      " -403.00487101 -420.73003612]\n",
      "order:  5 predict:  5\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/14_5.mat\n",
      "[ -85.78502997 -407.71144587 -368.92320428   52.36834488 -403.80852486\n",
      " -874.78419689 -449.46377735]\n",
      "order:  5 predict:  4\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/15_4.mat\n",
      "[-654.92823434 -665.81073737 -600.44901024  273.04794582 -253.80445951\n",
      " -646.44298084 -337.98028832]\n",
      "order:  4 predict:  4\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/16_6.mat\n",
      "[-867.44256666 -376.25769572 -413.82454453 -404.46809426 -672.70900858\n",
      "  786.58150504 -103.10902536]\n",
      "order:  6 predict:  6\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/17_5.mat\n",
      "[-340.91802516 -159.20790627 -700.83736025 -699.28447401  426.09121717\n",
      " -356.51640458 -762.19127057]\n",
      "order:  5 predict:  5\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/18_1.mat\n",
      "[ 459.14999736 -708.55950331 -624.34984597 -608.58446232  -43.69558124\n",
      " -692.31643195 -102.46636382]\n",
      "order:  1 predict:  1\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/19_2.mat\n",
      "[ -886.22776283  1787.74644366 -1152.60396119  -876.95511598\n",
      "  -986.20101972  -169.21625832  -839.01095885]\n",
      "order:  2 predict:  2\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/20_1.mat\n",
      "[ 1217.42791187  -596.61091464  -402.31097778  -327.88866945\n",
      "    64.63344499  -474.78218865 -1030.00693818]\n",
      "order:  1 predict:  1\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/21_2.mat\n",
      "[ -400.90642635  1380.38868528  -861.83729665 -1062.66657202\n",
      " -1182.16449939  -138.75312224  -570.79186068]\n",
      "order:  2 predict:  2\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/22_3.mat\n",
      "[-1028.07484443  -744.92750235   822.27985171  -343.29549144\n",
      "  -364.05031347  -842.13634944  -457.88273247]\n",
      "order:  3 predict:  3\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/23_4.mat\n",
      "[-449.49779335 -328.82783935 -862.07529495  959.51124192 -569.96191719\n",
      " -460.14454267 -176.82078858]\n",
      "order:  4 predict:  4\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/24_5.mat\n",
      "[-713.29206576 -454.17152941 -485.94768813 -427.6837632   588.53547941\n",
      " -487.14912232 -560.80028874]\n",
      "order:  5 predict:  5\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/25_3.mat\n",
      "[-551.71641005 -833.07285915 1142.87547833 -642.90743172 -535.76999635\n",
      " -981.9007706  -541.19920169]\n",
      "order:  3 predict:  3\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/26_3.mat\n",
      "[ -702.87493943 -1070.39026877  1032.40447647  -445.85947603\n",
      "  -310.64025383   101.76975487  -608.44103751]\n",
      "order:  3 predict:  3\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/27_1.mat\n",
      "[1011.41339407 -239.53905067 -595.52935002 -541.83730433 -457.74201914\n",
      " -823.74086613 -533.61504037]\n",
      "order:  1 predict:  1\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/28_1.mat\n",
      "[ 636.56432553 -594.18391976 -605.80008494 -863.64320964  208.61403578\n",
      " -390.65007178 -218.82357512]\n",
      "order:  1 predict:  1\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/29_2.mat\n",
      "[-353.91693449 1208.92777354 -555.01020463 -640.14105389 -656.48739571\n",
      " -565.72749436 -692.31416895]\n",
      "order:  2 predict:  2\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/30_3.mat\n",
      "[-477.06376289 -297.87107168  860.21092455 -860.21664429 -442.37620837\n",
      " -608.1807565  -920.7440058 ]\n",
      "order:  3 predict:  3\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/31_1.mat\n",
      "[ 1959.01961858  -493.482032    -840.02164508 -1002.33608749\n",
      "  -464.88364904  -481.2308227  -1152.30415579]\n",
      "order:  1 predict:  1\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/32_2.mat\n",
      "[-246.91384599  636.9172698  -844.50719085 -265.93619781 -496.87034349\n",
      " -860.16965252 -978.16758289]\n",
      "order:  2 predict:  2\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/33_6.mat\n",
      "[ -911.64746213  -623.39683577  -820.4413404  -1186.90970144\n",
      "  -322.89597563   820.61391227  -340.24046145]\n",
      "order:  6 predict:  6\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/34_4.mat\n",
      "[-600.09023925 -727.88795082 -502.31855583  373.83223865 -181.8206274\n",
      " -479.31737154 -256.1718798 ]\n",
      "order:  4 predict:  4\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/35_3.mat\n",
      "[-710.09805846 -679.55817234  693.36315411 -521.47757202 -492.645716\n",
      " -468.8071175  -726.11616129]\n",
      "order:  3 predict:  3\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/36_3.mat\n",
      "[-1324.88673034  -325.06865619  1833.45361747  -475.49617782\n",
      "  -468.86210082  -696.68258912  -840.29478645]\n",
      "order:  3 predict:  3\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/37_1.mat\n",
      "[1127.99296888 -773.36025707 -718.924343   -602.99587343 -264.32971461\n",
      " -761.21468649 -287.91401431]\n",
      "order:  1 predict:  1\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/38_1.mat\n",
      "[ 1122.75730666  -702.85321855  -108.37772602  -683.09231875\n",
      "  -579.0800424  -1007.39726894 -1143.74625668]\n",
      "order:  1 predict:  1\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/39_2.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -263.92423377   999.19922757  -972.16377357 -1025.7069267\n",
      "  -803.59755818  -578.93641695  -522.46146126]\n",
      "order:  2 predict:  2\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/40_7.mat\n",
      "[-1305.56668557   -18.81452256 -1401.20266979  -742.86130433\n",
      "  -423.21226856  -458.56110962  1072.18663311]\n",
      "order:  7 predict:  7\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/41_1.mat\n",
      "[ 753.71122505 -503.86909451 -615.9102274  -406.43797744 -149.62597663\n",
      " -619.8920542  -740.09769237]\n",
      "order:  1 predict:  1\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/42_2.mat\n",
      "[  292.13951499   893.80055356  -471.31005067  -424.72739373\n",
      "  -714.89259879  -783.25604266 -1037.13550047]\n",
      "order:  2 predict:  2\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/43_4.mat\n",
      "[ -871.32253829 -1148.65061807 -1019.19383861  1235.76902232\n",
      "  -257.1191508   -747.68306416  -655.2738849 ]\n",
      "order:  4 predict:  4\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/44_6.mat\n",
      "[-388.63770583 -581.08802999   71.04888815 -456.29963466 -231.17478081\n",
      "  637.15990004 -580.65712265]\n",
      "order:  6 predict:  6\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/45_6.mat\n",
      "[-823.74549715 -363.0909187  -582.2548891  -761.33274004 -407.85837049\n",
      " 1112.33763647 -658.69718023]\n",
      "order:  6 predict:  6\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/46_7.mat\n",
      "[-402.66650485 -262.95667295 -310.90727934 -815.19552189 -895.11574643\n",
      " -127.74911582 1037.15440379]\n",
      "order:  7 predict:  7\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/47_1.mat\n",
      "[ 1215.21124281   -49.80890915  -523.54317042  -974.96781424\n",
      "   -50.08264883 -1684.84830021 -1103.77953581]\n",
      "order:  1 predict:  1\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/48_5.mat\n",
      "[-199.15350468 -182.13732459 -624.94463764 -962.96036683 1733.06626779\n",
      " -333.5961542    15.75146426]\n",
      "order:  5 predict:  5\n",
      "/Users/hyuns/Desktop/HGU/2020-2/Capstone/Drone Project/EEGData/VR300_Data/0729/hs/Online/49_5.mat\n",
      "[-580.69887086 -425.49233918 -452.43432295 -575.44523396  772.16712114\n",
      " -623.50288804 -383.51462127]\n",
      "order:  5 predict:  5\n",
      "score: 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import butter, lfilter, sosfiltfilt\n",
    "import time\n",
    "import os, glob\n",
    "import hdf5storage\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.externals import joblib\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import socket\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "        nyq = 0.5 * fs\n",
    "        low = lowcut / nyq\n",
    "        high = highcut / nyq\n",
    "        b, a = butter(order, [low, high], btype='band')\n",
    "        return b, a\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "        b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "        y = lfilter(b, a, data)\n",
    "        return y\n",
    "\n",
    "def Standardization(Epochs):\n",
    "    for i in range(Epochs.shape[1]):\n",
    "        Epochs[:,i,:] = np.subtract(Epochs[:,i,:], np.mean(Epochs[:,i,:]))\n",
    "        Epochs[:,i,:] = Epochs[:,i,:] / np.std(Epochs[:,i,:])\n",
    "    \n",
    "    return Epochs    \n",
    "\n",
    "def Make_Average_Component(Epochs, AverSize):\n",
    "    Num = int(np.floor(Epochs.shape[0]/AverSize))\n",
    "    \n",
    "    Epochs_Aver = np.zeros((Num, Epochs.shape[1], Epochs.shape[2]))\n",
    "    for i in range(Num):\n",
    "        Epochs_Aver[i, :, :] = np.mean(Epochs[AverSize*i:AverSize*i+AverSize, :, :], axis=0)\n",
    "    \n",
    "    return Epochs_Aver\n",
    "    \n",
    "def Epoching(eegData, stims, code, samplingRate, nChannel, epochSampleNum, epochOffset,baseline):\n",
    "        Time = stims[np.where(stims[:,1] == code),0][0]\n",
    "        Time = np.floor(np.multiply(Time,samplingRate)).astype(int)\n",
    "        Time_after = np.add(Time,epochOffset).astype(int)\n",
    "        Time_base = np.add(Time,baseline).astype(int)\n",
    "        Num = Time.shape\n",
    "        Epochs = np.zeros((Num[0], nChannel, epochSampleNum))\n",
    "        for j in range(Num[0]):\n",
    "            Epochs[j, :, :] = eegData[:, Time_after[j]:Time_after[j] + epochSampleNum]\n",
    "        \n",
    "        Epochs = Standardization(Epochs)\n",
    "        Epochs_Aver = np.mean(Epochs, axis=0)\n",
    "\n",
    "        return Epochs_Aver\n",
    "\n",
    "def Convert_to_FeatureVector(Epochs, buttonNum, featureNum):\n",
    "    Features = np.zeros((buttonNum, featureNum))\n",
    "    for i in range(buttonNum):\n",
    "        Features[i, :] = np.reshape(Epochs[i, :, :], (1, featureNum))\n",
    "    return Features\n",
    "    \n",
    "def main():\n",
    "        Classifier_path = '/Users/hyuns/Desktop/LDAModel/'\n",
    "        classifier_list = sorted(glob.glob(Classifier_path + '*.pickle'), key=os.path.getmtime, reverse=True)\n",
    "        print(\"classifer:\", classifier_list[0])\n",
    "        \n",
    "        lda = joblib.load(classifier_list[0])\n",
    "        \n",
    "        mat_path = root_path + 'Online/'\n",
    "        current_list = sorted(glob.glob(mat_path + '*.mat'), key=os.path.getmtime, reverse=True)\n",
    "        score = 0\n",
    "        \n",
    "        for mat_file in current_list:\n",
    "            print(mat_file)\n",
    "            ans = mat_file[-5]\n",
    "            \n",
    "            mat = hdf5storage.loadmat(mat_file)\n",
    "            channelNames = mat['channelNames']\n",
    "            eegData = mat['eegData']\n",
    "            samplingFreq = mat['samplingFreq']\n",
    "            samplingFreq = samplingFreq[0,0]\n",
    "            stims = mat['stims']\n",
    "            channelNum = channelNames.shape\n",
    "            channelNum = channelNum[1]\n",
    "            eegData = np.transpose(eegData)\n",
    "            buttonNum = 7\n",
    "            \n",
    "            #Bandpass Filter\n",
    "            eegData = butter_bandpass_filter(eegData, 0.1, 30, samplingFreq, order=4)\n",
    "\n",
    "            #Epoching\n",
    "            epochSampleNum = int(np.floor(1.0 * samplingFreq))\n",
    "            offset = int(np.floor(0.0 * samplingFreq))\n",
    "            baseline = int(np.floor(1.0 * samplingFreq))\n",
    "            \n",
    "            ####### averaging whole epochs\n",
    "            Epochs_Aver = np.zeros((buttonNum, channelNum, epochSampleNum))\n",
    "            \n",
    "            featureNum = channelNum*epochSampleNum\n",
    "            \n",
    "            for i in range(buttonNum):\n",
    "                Epochs_Aver[i] = Epoching(eegData, stims, (i+1), samplingFreq, channelNum, epochSampleNum, offset, baseline)\n",
    "         \n",
    "            Features = Convert_to_FeatureVector(Epochs_Aver, buttonNum, featureNum)\n",
    "        \n",
    "            Answers = lda.decision_function(Features)\n",
    "            answer = np.argmax(Answers) + 1\n",
    "            \n",
    "            print(Answers)\n",
    "            if int(ans) != int(answer): \n",
    "                score = score + 1\n",
    "            print('order: ', ans, 'predict: ', answer)\n",
    "        \n",
    "        print('score:', score)\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
